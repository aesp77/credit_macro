{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# P&L Reconstruction and Data Quality Fixes\n",
        "\n",
        "This notebook addresses historical data issues and reconstructs accurate P&L."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modules imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from src.data import BloombergCDSConnector, CDSDataManager\n",
        "from src.models import CDSDatabase, Position, Strategy, Side\n",
        "\n",
        "print('Modules imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Historical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading S40_5Y...\n",
            "  Loaded 249 days\n",
            "Loading S41_5Y...\n",
            "  Loaded 257 days\n",
            "Loading S42_5Y...\n",
            "  Loaded 257 days\n",
            "Loading S43_5Y...\n",
            "  Loaded 129 days\n",
            "\n",
            "Total series loaded: 4\n"
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "connector = BloombergCDSConnector()\n",
        "db = CDSDatabase('../data/cds_monitor.db')\n",
        "manager = CDSDataManager(connector, db)\n",
        "\n",
        "# Load 6 months of data\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=360)\n",
        "\n",
        "# Load data for multiple series\n",
        "series_list = [40, 41, 42, 43]\n",
        "historical_data = {}\n",
        "\n",
        "for series in series_list:\n",
        "    ticker = connector.get_index_ticker('EU', 'IG', series, '5Y')\n",
        "    key = f'S{series}_5Y'\n",
        "    \n",
        "    print(f'Loading {key}...')\n",
        "    data = connector.get_historical_spreads(\n",
        "        ticker, \n",
        "        start_date=start_date,\n",
        "        end_date=end_date\n",
        "    )\n",
        "    \n",
        "    if not data.empty:\n",
        "        historical_data[key] = data\n",
        "        print(f'  Loaded {len(data)} days')\n",
        "\n",
        "print(f'\\nTotal series loaded: {len(historical_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "S40_5Y Quality Check:\n",
            "  Missing values: 0\n",
            "  Zero spreads: 0\n",
            "  Mean: 45.66 bps\n",
            "  Std: 5.67 bps\n",
            "\n",
            "S41_5Y Quality Check:\n",
            "  Missing values: 0\n",
            "  Zero spreads: 0\n",
            "  Mean: 48.50 bps\n",
            "  Std: 5.24 bps\n",
            "\n",
            "S42_5Y Quality Check:\n",
            "  Missing values: 0\n",
            "  Zero spreads: 0\n",
            "  Mean: 55.10 bps\n",
            "  Std: 5.39 bps\n",
            "\n",
            "S43_5Y Quality Check:\n",
            "  Missing values: 0\n",
            "  Zero spreads: 0\n",
            "  Mean: 58.55 bps\n",
            "  Std: 7.05 bps\n"
          ]
        }
      ],
      "source": [
        "# Check for data quality issues\n",
        "for key, data in historical_data.items():\n",
        "    print(f'\\n{key} Quality Check:')\n",
        "    \n",
        "    # Missing values\n",
        "    missing = data.isnull().sum().sum()\n",
        "    print(f'  Missing values: {missing}')\n",
        "    \n",
        "    # Zero spreads\n",
        "    if 'px_last' in data.columns:\n",
        "        zeros = (data['px_last'] == 0).sum()\n",
        "        print(f'  Zero spreads: {zeros}')\n",
        "        \n",
        "        # Statistics\n",
        "        print(f'  Mean: {data[\"px_last\"].mean():.2f} bps')\n",
        "        print(f'  Std: {data[\"px_last\"].std():.2f} bps')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned S40_5Y\n",
            "Cleaned S41_5Y\n",
            "Cleaned S42_5Y\n",
            "Cleaned S43_5Y\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\alessandro.esposito\\AppData\\Local\\Temp\\ipykernel_18592\\491350071.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  cleaned = cleaned.fillna(method='ffill').fillna(method='bfill')\n",
            "C:\\Users\\alessandro.esposito\\AppData\\Local\\Temp\\ipykernel_18592\\491350071.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  cleaned['px_last'] = cleaned['px_last'].fillna(method='ffill')\n"
          ]
        }
      ],
      "source": [
        "def clean_spread_data(data):\n",
        "    '''Clean and fix spread data'''\n",
        "    cleaned = data.copy()\n",
        "    \n",
        "    # Handle missing values\n",
        "    cleaned = cleaned.fillna(method='ffill').fillna(method='bfill')\n",
        "    \n",
        "    # Fix zero spreads\n",
        "    if 'px_last' in cleaned.columns:\n",
        "        cleaned.loc[cleaned['px_last'] == 0, 'px_last'] = np.nan\n",
        "        cleaned['px_last'] = cleaned['px_last'].fillna(method='ffill')\n",
        "    \n",
        "    return cleaned\n",
        "\n",
        "# Clean all series\n",
        "cleaned_data = {}\n",
        "for key, data in historical_data.items():\n",
        "    cleaned_data[key] = clean_spread_data(data)\n",
        "    print(f'Cleaned {key}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Reconstruct P&L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Historical Position P&L:\n",
            "Entry spread: 55.35 bps\n",
            "Current spread: 50.44 bps\n",
            "Spread change: -4.91 bps\n",
            "P&L: $22,077,000\n"
          ]
        }
      ],
      "source": [
        "# Example P&L reconstruction for a historical position\n",
        "if 'S43_5Y' in cleaned_data:\n",
        "    data = cleaned_data['S43_5Y']\n",
        "\n",
        "    # Assume we bought protection 30 days ago\n",
        "    entry_idx = -30\n",
        "    if len(data) > 30 and 'px_last' in data.columns:\n",
        "        entry_spread = data['px_last'].iloc[entry_idx]\n",
        "        current_spread = data['px_last'].iloc[-1]\n",
        "        \n",
        "        # Calculate P&L (assuming $10mm notional, 4500 DV01)\n",
        "        notional = 10_000_000\n",
        "        dv01 = 4500\n",
        "        spread_change = current_spread - entry_spread\n",
        "        pnl = -spread_change * dv01 * notional / 10000\n",
        "        \n",
        "        print('Historical Position P&L:')\n",
        "        print(f'Entry spread: {entry_spread:.2f} bps')\n",
        "        print(f'Current spread: {current_spread:.2f} bps')\n",
        "        print(f'Spread change: {spread_change:.2f} bps')\n",
        "        print(f'P&L: ${pnl:,.0f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
