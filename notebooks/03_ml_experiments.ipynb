{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning for CDS Spread Prediction\n",
        "\n",
        "This notebook implements ML models for spread prediction and regime detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modules imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Our modules\n",
        "from src.data import BloombergCDSConnector, CDSDataManager\n",
        "from src.models import Region, Market, Tenor\n",
        "\n",
        "print('Modules imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Historical Data for ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for ITRX EUR CDSI S43 5Y...\n",
            "Loaded 129 days of data\n",
            "            px_last\n",
            "2025-03-20   58.645\n",
            "2025-03-21   60.163\n",
            "2025-03-24   58.253\n",
            "2025-03-25   57.523\n",
            "2025-03-26   58.714\n"
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "connector = BloombergCDSConnector()\n",
        "manager = CDSDataManager(connector)\n",
        "\n",
        "# Load 1 year of data for ML training\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=365)\n",
        "current_series = 43\n",
        "\n",
        "# Fetch data\n",
        "ticker = connector.get_index_ticker('EU', 'IG', current_series, '5Y')\n",
        "print(f'Loading data for {ticker}...')\n",
        "\n",
        "hist_data = connector.get_historical_spreads(\n",
        "    ticker,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    fields=['px_last', 'volume']\n",
        ")\n",
        "\n",
        "if not hist_data.empty:\n",
        "    print(f'Loaded {len(hist_data)} days of data')\n",
        "    print(hist_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 12 features\n",
            "Features: ['px_last', 'returns', 'ma_5', 'volatility_5', 'ma_10', 'volatility_10', 'ma_20', 'volatility_20', 'lag_1', 'lag_2', 'lag_3', 'lag_5']\n"
          ]
        }
      ],
      "source": [
        "def create_features(df, window_sizes=[5, 10, 20]):\n",
        "    '''Create technical features for ML'''\n",
        "    features = df.copy()\n",
        "    \n",
        "    # Price features\n",
        "    features['returns'] = features['px_last'].pct_change()\n",
        "    \n",
        "    # Moving averages\n",
        "    for window in window_sizes:\n",
        "        features[f'ma_{window}'] = features['px_last'].rolling(window).mean()\n",
        "        features[f'volatility_{window}'] = features['returns'].rolling(window).std()\n",
        "    \n",
        "    # Lag features\n",
        "    for lag in [1, 2, 3, 5]:\n",
        "        features[f'lag_{lag}'] = features['px_last'].shift(lag)\n",
        "    \n",
        "    # Drop NaN rows\n",
        "    features = features.dropna()\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Create features\n",
        "if not hist_data.empty:\n",
        "    ml_data = create_features(hist_data)\n",
        "    print(f'Created {len(ml_data.columns)} features')\n",
        "    print('Features:', ml_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Prediction Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance:\n",
            "RMSE: 1.610 bps\n",
            "MAE: 1.244 bps\n",
            "R²: 0.158\n"
          ]
        }
      ],
      "source": [
        "# Prepare data for ML\n",
        "if 'ml_data' in locals() and not ml_data.empty:\n",
        "    # Define target: next day spread\n",
        "    ml_data['target'] = ml_data['px_last'].shift(-1)\n",
        "    ml_data = ml_data.dropna()\n",
        "    \n",
        "    # Select features\n",
        "    feature_cols = [col for col in ml_data.columns \n",
        "                   if col not in ['px_last', 'target', 'volume']]\n",
        "    \n",
        "    X = ml_data[feature_cols]\n",
        "    y = ml_data['target']\n",
        "    \n",
        "    # Split data\n",
        "    split_point = int(len(X) * 0.8)\n",
        "    X_train = X[:split_point]\n",
        "    X_test = X[split_point:]\n",
        "    y_train = y[:split_point]\n",
        "    y_test = y[split_point:]\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Train model\n",
        "    model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    test_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Metrics\n",
        "    mse = mean_squared_error(y_test, test_pred)\n",
        "    mae = mean_absolute_error(y_test, test_pred)\n",
        "    r2 = r2_score(y_test, test_pred)\n",
        "    \n",
        "    print('Model Performance:')\n",
        "    print(f'RMSE: {np.sqrt(mse):.3f} bps')\n",
        "    print(f'MAE: {mae:.3f} bps')\n",
        "    print(f'R²: {r2:.3f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
